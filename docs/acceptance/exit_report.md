# Informe de salida

## Resumen Ejecutivo

Este proyecto ha desarrollado el código para la implementación y comparación de 2 modelos para la tarea Image Captioning.

## Resultados del proyecto

Durante el proyecto, se han implementado 2 modelos, basados en CNN y LSTM, para la tarea de Image Captioning. Para esto se utilizó una muestra de la colección de Flickr 8K. Se calcularon las métricas Blue score y Meteor score para la evaluación de los modelos, mostrando el primer modelo mejores resultados.

## Lecciones aprendidas

Aunque el modelo genera descripciones relacionadas a las imágenes que se le proporciona, puede mejorar en su desempeño. Para futuras actualizaciones, se recomienda utilizar la totalidad de la colección de datos disponibles y no sólo una muestra.

## Impacto del proyecto

Image captioning potencialmente puede ser usado para mejorar las interfaces de usuario de aplicaciones basadas en imágenes, aumentando la accesibilidad de contenidos visuales y enriquecer las capacidades analíticas de datos visuales. El presente proyecto permite tener una prueba de cómo se pueden implementar técnicas de deep learning con esta finalidad.

## Conclusiones

El proyecto demostró que los modelos de deep learning pueden generar descripciones de imágenes. Los resultados muestran que la metodología empleada, aunque puede mejorarse, es válida para la tarea de Image Captioning.

## Agradecimientos

Quiero expresar mi agradecimiento a los profesores del curso por la enseñanza de este fascinante tema y por compartir su experiencia sobre las diferentes metodologías y herramientas actuales para el desarrollo de aplicaciones con Machine Learning.
